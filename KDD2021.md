# KDD2021報告

## Are we really making much progress?: Revisiting, benchmarking and refining heterogeneous graph neural networks
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467350)

### 概要
Heterogeneous Graph Neural Network (HGNN) のベンチマークデータセットである
[Heterogeneous Graph Benchmark (HGB)](https://github.com/THUDM/HGB) を整備した。

このレポジトリで、3つのタスクの、全部で11のデータセットを使い、
これまで公開された複数の手法を使って精度比較をした報告

Are we really making much progress? はいわずもがな
MaurizioFD氏による Are We Really Making Much Progress?
A Worrying Analysis of Recent Neural Recommendation Approaches
が念頭にあり、Graph Neural Network の最近の進展を批判的に
取り上げた論文である。

様々な手法が最近提案されているが、これまでの手法の中で
最も精度が高かったのは、ほとんどがGATという初期の方法のケースで、
さらにGATを若干拡張した手法である、Simple-HGNという（単純な）手法が
最も精度が高かったという報告となっている。

## Learning Based Proximity Matrix Factorization for Node Embedding
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467296)
- 実装がない。

### 概要
Node Embedding の算出方法の提案。Lameneという名前。
Personalized PageRank におけるスタートに戻る確率を、各時刻において
一律でない値を採用し、これを学習するもの。
学習には、Differentiable SVD を採用する。PyTorchを利用。
ただし計算コストが高く、コストがかからないような工夫があるため、
ロジックが若干ややこしい。

計算した結果得られる Node Embedding による各タスクの精度は
他の手法よりも高い。既存の手法で最も高いものとして STRAP という
手法があるらしい。

## Signed Graph Neural Network with Latent Groups
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467355)
- [実装](https://github.com/haoxin1998/GS-GNN)  ... まだ公開されていない感じ。

### 概要
敵・味方のネットワークで、node representation を得ようという話。
「味方の味方は味方」「敵の敵は味方」となっているように友達関係が
構成されるという "balance theory" (バランス理論) に基づいて愚直に
representation を構成しようとすると破綻するので、ある程度グループ
にまとめてしまい、グループ内で representation が似ていて、
そこから敵・味方関係の矛盾が少なくなるように representation を
算出するアルゴリズム GS-GNN を構成した。

## Approximate Graph Propagation
- [論文](https://dl.acm.org/doi/pdf/10.1145/3447548.3467243)
- [著者github](https://github.com/wanghzccls/) ... ただし実装がない

### 概要
Graph Propagation に基づく Node Representation の手法として、
Personalized PageRank (PPR), heat kernel, Katz などの手法があるが
これらを統合したうえで、さらに近似計算で高速化した改良手法の提案

各種手法との精度・計算時間の比較グラフを見ると、
既存手法より10倍前後程度速くて、かつ既存手法より若干精度が劣る
程度にとどめられるとのこと。

## Maximizing Influence of Leaders in Social Networks
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467229)
- [実装](https://github.com/kedges/kedges)

### 概要
二極化した世論(0/1)で、人々の意見は身近な知り合いの意見の平均で
決まる、とするネットワーク上のダイナミクスモデル（これを一般的に
Leader-Follower DeGroot Modelというらしい）が与えられたときに、
初期条件として1の意見をもつ人達(leaders)から、0の意見を持つ人たち
(follower)に対して、任意にedgeをつないでいい時に、その本数が固定の
場合に、最もダイナミクスを無限回回した時の1の意見を持つ人の割合
が最大になるようなedgeの結び方の提案。

このようなedgeの選び方は submodular 性をもつので、greedy に選択
しても、ある程度精度が担保でき、かつ、1本追加で選んだ時の
1の割合は、逆行列を使った更新式 (Sherman-Morrison formula) で
更新できる。

Julia を使った実装が存在する。

## MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467231)
- [実装](https://github.com/angus924/minirocket)

### 概要
時系列に対する判別モデル。
Convolution Kernel の作り方がうまくて、いろんなパターンのKernelを
長さを引き延ばしてたくさん作る。
先行する手法の Rocket と似ているが、乱数を使わない決定的手法。
Rocketと比較して精度を維持しつつ75倍速くなったといっている。

KDDに先行してすでに実装があったらしい。
sklearnと親和性が高く見える。

## A Broader Picture of Random-walk Based Graph Embedding
- [論文](https://dl.acm.org/doi/abs/10.1145/3447548.3467300)
- [実装](https://github.com/zexihuang/random-walk-embedding)

### 概要
これまでに提案されてきた Random-walk を用いる Graph Embedding 手法を
次の3つの要素で特徴づけて分類:

- 1. 遷移確率の取り方(連結要素だけに行くか, PageRankのようにジャンプがあるか)
- 2. ノード間の類似度の計算の仕方(PMI or Autocovariance)
- 3. ノードembeddingの算出方法(Matrix Factorization or Sampling)

これらの要素の組み合わせでまだ検証していない組み合わせについて
複数のデータセット・タスクで検証を改めて実施。

実際には、タスクごとに適した組み合わせがあり、例えば、
- PMI vs Autocovariance では、
  - Node Classification では、PMIが性能高い
  - Link Prediction では、AutoCovarianceが性能高い
その他、3つの要素いずれについても、タスクごとにどちらが優れて
いるかはタスクによって変わるので、タスクによってそれぞれの要素
のどれがいいか選択するべきである、という趣旨らしい。

Graph Embedding については、上の "Approximate Graph Propagation"
と同じく、手法がかなり発散していて、このような整理学が求められて
いるという雰囲気がある。

## Where are we in embedding spaces? A Comprehensive Analysis on Network Embedding Approaches for Recommender Systems
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467421),[arxiv](https://arxiv.org/abs/2105.08908)
- [実装](https://github.com/RinneSz/Social-Collaborative-Metric-Learning)

### 概要
レコメンドタスクでHyperbolic embeddingがどれだけ有効かを
ちゃんと調べてみようという研究。practitionerは、なんでも
hyperbolic化したがるけど、そうなんでもhyperbolicにしたからと
いってよくなるわけではないよという前置きから始まる。

3つの仮定を置き、実際のデータで仮説が正しいことを確認している。

- 1. inner product based の手法より distance based の手法のほうが改善が大きい。
- 2. データの密度が低い場合に hyperbolic 化での改善が大きい。
- 3. hyperbolic の場合は、しない場合と比較して次元が低いほうが改善が大きい。

「データの密度が低い」は、行列密度が、0.01%-0.1%程度のスケールを指している。
MovieLensは100k-1Mは、4-6%程度であり、密度が高いケースになる。

実際にSocial Network で、これらの仮定が当てはまるような
CMLの拡張手法 SCML と hyperbolic 化した HSCMF を提案し
確かに従来法よりも精度が改善することを確認。
ただし計算コストが高いので、注意したほうがいいというコメント。

レコメンドタスクでは、hyperbolic化により精度改善ができるケースが
比較的限られているので注意したほうがいいという指摘に見えた。

## News
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467392)
- 実装はない。
  - first author である Jialu Liu の [github](https://github.com/remenberl)にも実装は見当たらない。 

### 概要
News記事のembeddingを算出する話であるが、様々な工夫がある。

- 事前学習済みのtransformerモデルを用いること
- news記事1つに対してまったく同じだが表現が違うもの(positive)と
  よく似ているが、まったく別の記事(negative)でtripletを構成し、
  contrastive learning で embedding をする。
- この学習において、news記事に対して付与されている
  記事カテゴリの判別タスクも含めて学習を実施し、
  multitask learning をして精度を高めている。

単にcontrastive learning するだけではなく、
multitaskにして精度を高めたりするあたりの工夫が光る。

またデータをクロールする際に、記事の時刻と、
記事についた画像のembeddingsにより、記事の同一性を担保するなど、
データの集め方やラベルのつけ方が素晴らしい。パイプラインの構成など、
学習システムの構築など非常に鮮やかな感じがする。
