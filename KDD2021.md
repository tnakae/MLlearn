# KDD2021報告

## Are we really making much progress?: Revisiting, benchmarking and refining heterogeneous graph neural networks
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467350)

### 概要
Heterogeneous Graph Neural Network (HGNN) のベンチマークデータセットである
[Heterogeneous Graph Benchmark (HGB)](https://github.com/THUDM/HGB) を整備した。

このレポジトリで、3つのタスクの、全部で11のデータセットを使い、
これまで公開された複数の手法を使って精度比較をした報告

Are we really making much progress? はいわずもがな
MaurizioFD氏による Are We Really Making Much Progress?
A Worrying Analysis of Recent Neural Recommendation Approaches
が念頭にあり、Graph Neural Network の最近の進展を批判的に
取り上げた論文である。

様々な手法が最近提案されているが、これまでの手法の中で
最も精度が高かったのは、ほとんどがGATという初期の方法のケースで、
さらにGATを若干拡張した手法である、Simple-HGNという（単純な）手法が
最も精度が高かったという報告となっている。

## Learning Based Proximity Matrix Factorization for Node Embedding
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467296)
- 実装がない。

### 概要
Node Embedding の算出方法の提案。Lameneという名前。
Personalized PageRank におけるスタートに戻る確率を、各時刻において
一律でない値を採用し、これを学習するもの。
学習には、Differentiable SVD を採用する。PyTorchを利用。
ただし計算コストが高く、コストがかからないような工夫があるため、
ロジックが若干ややこしい。

計算した結果得られる Node Embedding による各タスクの精度は
他の手法よりも高い。既存の手法で最も高いものとして STRAP という
手法があるらしい。

## Signed Graph Neural Network with Latent Groups
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467355)
- [実装](https://github.com/haoxin1998/GS-GNN)  ... まだ公開されていない感じ。

### 概要
敵・味方のネットワークで、node representation を得ようという話。
「味方の味方は味方」「敵の敵は味方」となっているように友達関係が
構成されるという "balance theory" (バランス理論) に基づいて愚直に
representation を構成しようとすると破綻するので、ある程度グループ
にまとめてしまい、グループ内で representation が似ていて、
そこから敵・味方関係の矛盾が少なくなるように representation を
算出するアルゴリズム GS-GNN を構成した。

## Approximate Graph Propagation
- [論文](https://dl.acm.org/doi/pdf/10.1145/3447548.3467243)
- [著者github](https://github.com/wanghzccls/) ... ただし実装がない

### 概要
Graph Propagation に基づく Node Representation の手法として、
Personalized PageRank (PPR), heat kernel, Katz などの手法があるが
これらを統合したうえで、さらに近似計算で高速化した改良手法の提案

各種手法との精度・計算時間の比較グラフを見ると、
既存手法より10倍前後程度速くて、かつ既存手法より若干精度が劣る
程度にとどめられるとのこと。

## Maximizing Influence of Leaders in Social Networks
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467229)
- [実装](https://github.com/kedges/kedges)

### 概要
二極化した世論(0/1)で、人々の意見は身近な知り合いの意見の平均で
決まる、とするネットワーク上のダイナミクスモデル（これを一般的に
Leader-Follower DeGroot Modelというらしい）が与えられたときに、
初期条件として1の意見をもつ人達(leaders)から、0の意見を持つ人たち
(follower)に対して、任意にedgeをつないでいい時に、その本数が固定の
場合に、最もダイナミクスを無限回回した時の1の意見を持つ人の割合
が最大になるようなedgeの結び方の提案。

このようなedgeの選び方は submodular 性をもつので、greedy に選択
しても、ある程度精度が担保でき、かつ、1本追加で選んだ時の
1の割合は、逆行列を使った更新式 (Sherman-Morrison formula) で
更新できる。

Julia を使った実装が存在する。

## MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467231)
- [実装](https://github.com/angus924/minirocket)

### 概要
時系列に対する判別モデル。
Convolution Kernel の作り方がうまくて、いろんなパターンのKernelを
長さを引き延ばしてたくさん作る。
先行する手法の Rocket と似ているが、乱数を使わない決定的手法。
Rocketと比較して精度を維持しつつ75倍速くなったといっている。

KDDに先行してすでに実装があったらしい。
sklearnと親和性が高く見える。

## A Broader Picture of Random-walk Based Graph Embedding
- [論文](https://dl.acm.org/doi/abs/10.1145/3447548.3467300)
- [実装](https://github.com/zexihuang/random-walk-embedding)

### 概要
これまでに提案されてきた Random-walk を用いる Graph Embedding 手法を
次の3つの要素で特徴づけて分類:

- 1. 遷移確率の取り方(連結要素だけに行くか, PageRankのようにジャンプがあるか)
- 2. ノード間の類似度の計算の仕方(PMI or Autocovariance)
- 3. ノードembeddingの算出方法(Matrix Factorization or Sampling)

これらの要素の組み合わせでまだ検証していない組み合わせについて
複数のデータセット・タスクで検証を改めて実施。

実際には、タスクごとに適した組み合わせがあり、例えば、
- PMI vs Autocovariance では、
  - Node Classification では、PMIが性能高い
  - Link Prediction では、AutoCovarianceが性能高い
その他、3つの要素いずれについても、タスクごとにどちらが優れて
いるかはタスクによって変わるので、タスクによってそれぞれの要素
のどれがいいか選択するべきである、という趣旨らしい。

Graph Embedding については、上の "Approximate Graph Propagation"
と同じく、手法がかなり発散していて、このような整理学が求められて
いるという雰囲気がある。

## Where are we in embedding spaces? A Comprehensive Analysis on Network Embedding Approaches for Recommender Systems
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467421),[arxiv](https://arxiv.org/abs/2105.08908)
- [実装](https://github.com/RinneSz/Social-Collaborative-Metric-Learning)

### 概要
レコメンドタスクでHyperbolic embeddingがどれだけ有効かを
ちゃんと調べてみようという研究。practitionerは、なんでも
hyperbolic化したがるけど、そうなんでもhyperbolicにしたからと
いってよくなるわけではないよという前置きから始まる。

3つの仮定を置き、実際のデータで仮説が正しいことを確認している。

- 1. inner product based の手法より distance based の手法のほうが改善が大きい。
- 2. データの密度が低い場合に hyperbolic 化での改善が大きい。
- 3. hyperbolic の場合は、しない場合と比較して次元が低いほうが改善が大きい。

「データの密度が低い」は、行列密度が、0.01%-0.1%程度のスケールを指している。
MovieLensは100k-1Mは、4-6%程度であり、密度が高いケースになる。

実際にSocial Network で、これらの仮定が当てはまるような
CMLの拡張手法 SCML と hyperbolic 化した HSCMF を提案し
確かに従来法よりも精度が改善することを確認。
ただし計算コストが高いので、注意したほうがいいというコメント。

レコメンドタスクでは、hyperbolic化により精度改善ができるケースが
比較的限られているので注意したほうがいいという指摘に見えた。

## News
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467392)
- 実装はない。
  - first author である Jialu Liu の [github](https://github.com/remenberl)にも実装は見当たらない。 

### 概要
News記事のembeddingを算出する話であるが、様々な工夫がある。

- 事前学習済みのtransformerモデルを用いること
- news記事1つに対してまったく同じだが表現が違うもの(positive)と
  よく似ているが、まったく別の記事(negative)でtripletを構成し、
  contrastive learning で embedding をする。
- この学習において、news記事に対して付与されている
  記事カテゴリの判別タスクも含めて学習を実施し、
  multitask learning をして精度を高めている。

単にcontrastive learning するだけではなく、
multitaskにして精度を高めたりするあたりの工夫が光る。

またデータをクロールする際に、記事の時刻と、
記事についた画像のembeddingsにより、記事の同一性を担保するなど、
データの集め方やラベルのつけ方が素晴らしい。パイプラインの構成など、
学習システムの構築など非常に鮮やかな感じがする。

## Triplet Attention: Rethinking the similarity in Transformers
- [論文](https://dl.acm.org/doi/abs/10.1145/3447548.3467241)
- [実装](https://github.com/zhouhaoyi/TripletAttention) ... これを書いた時点では *We will release the code soon.* となっている

### 概要
Transformers モデルの Self-Attention の部分で、
Query,Key,Value のKeyの部分にKey1,Key2と拡張する。
この際に、Key1,Key2のOuter-productとQueryとのinner productが
大きい場合に値が大きいとする考え方。このようにすると文脈ごとに
意味が異なる表現を取り込めるという話らしい。

![](./images/KDD2021/Triplet_Attention.png)

ただしこの機構を取り入れて改善できた差分はあまりそこまで
大きくないし、定性的に何か新しいことが抽出できるという
わけでもなさそうなので、あまりインパクトがないのではという印象。

## Efficient Data-specific Model Search for Collaborative Filtering
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467399)
- 実装はみあたらない。

### 概要
Collaborative Filteringを改良した手法は、Embeddingの算出や
inner productの算出部分に改良が加わっているという違いがあるだけ
なので、これらを適用する/しないをデータごとにパラメータチューニング
することで、データごとに特化した最適手法を抽出できるという前提で
組まれたレコメンド向け自動モデルチューニング機構についての報告。

![](./images/KDD2021/Efficient_RS.png)

心躍るタイトルで読み始めたのだが、前提として、Xiangnan He の
[Neural Collaborative Filtering](https://arxiv.org/abs/1708.05031)
の精度が高いことを期待しているのだが、残念ながら NCF は Steffen Rendle
さんが[RecSys2020で、シンプルなMatrix Factorizationより精度が低い](https://dl.acm.org/doi/10.1145/3383313.3412488)
というかなり辛らつだが確からしい実験報告が存在するあるので、この手の論文も
Matrix Factorization 系のモデルについてチューニングが正しくされているか
怪しい感じがある。コンセプトは理解するが結果については信憑性に欠くのでは
というのが素朴な印象。

## Deconfounded Recommendation for Alleviating Bias Amplification
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467249)
- [実装](https://github.com/WenjieWWJ/DecRS)

### 概要
レコメンドにおけるPopularity Biasの除外を因果推論の立場から考えた研究。
手法として、Factorization Machineとその亜種の改善が念頭にある。

User Embedding $U$ とUser Response $Y$ の両方に対して、
Item Groupへの直近の接触の多さという交絡因子が存在するため、
Popularity Biasが発生するという因果を仮定するところが出発点。

ここから、User Embedding $U$ や、Item Embedding $I$ とは独立に
「Item Group滞在分布」という変数 $D$ を FM モデルに入れて、
交絡因子の無効化(Deconfounding)を実施する DecRS を提案。
実際には、Item GroupごとのEmbedding $M$ を作って、$U,I,M$の
3つ組でモデルの中に組み込むという形をとる。

![](./images/KDD2021/Deconfounded.png)

交絡因子の仮定までは理解だが、その後の取り扱い方が因果推論系では
あまり一般的なやり方でないように見えるので、これで交絡因子を考慮した
因果推論として成立しているのかがよくわからない。手法を適用した後の
効果推定が通常のnDCGになっているのも、これで妥当なのかが疑問。
ただしシンプルなので、実運用には使いやすそう。

効果が表れやすいuserとして、Item Groupの季節変動が著しいuserへの
効果が表れやすいという話が面白い指摘に思った。
(レコメンド結果で行動に対してバイアスがかかりやすい人ほど
popularity bias補正の効果が出やすいという指摘)

Xiangnan He さんはこの方向性に舵を切ってきたらしい。。

## TimeSHAP: Explaining Recurrent Models through Sequence Perturbations
- [論文](https://dl.acm.org/doi/10.1145/3447548.3467166)
- 実装は見当たらない

### 概要
SHAPは、回帰/判別モデルでの説明変数の重要度の算出に用いる手法で、
LIMEと並んでよくつかわれるが、計算オーダーが変数の数の指数オーダーに
なる点が懸念点であるため、時系列イベントデータに使うにはコストが高い。

そこで、TimeSHAPと呼ばれる次の工夫を入れた。
(SHAPはそのままに、SHAPに入力するデータの入れ方の工夫だけにみえる)

1. 時系列データを現在から一定時刻前と後で2分割して扱ってSHAPで
   shapley値を計算し、最も効果の高い分割を見つける。
   (過去時刻の探索を効率化するpruning)
2. 決定した時刻より前の変数について、時刻ごと/変数ごとにグループ分けし
   最も効果のある組み合わせを見つける（時刻x変数の全組み合わせを
   探すと破綻するので。図）

![](./images/KDD2021/TimeSHAP.png)

この手順を、実際の（おそらくポルトガルに拠点がある）銀行のトランザクションの
GRUによる（おそらく異常利用の）判別モデルに適用し、どの時刻のどの特徴量が
判別に影響があるかを算出できたといっている。

ADS Track (Industrial Track相当)での発表なので、
実業務への適用実績に力点があり、技術的に新しい何かがある報告ではないが、
比較的シンプルな工夫でうまく効果を出せているように見える。

## Amazon SageMaker Clarify: Machine Learning Bias Detection and Explainability in the Cloud

- [論文](https://dl.acm.org/doi/10.1145/3447548.3467177)
- [Amazon SageMaker Clarify のページ](https://aws.amazon.com/jp/sagemaker/clarify/)

### 概要
Amazon SageMakerにdeployしたモデルと、学習に用いたデータセットを使って、
モデルに含まれる (バイアスがかかりがちな事前指定した特定の属性に対する)
バイアスの定量化と、予測根拠となる説明結果を与える Amazon SageMaker
Clarify というサービスについての紹介。

学習データ自体の偏り(Pre-Training Metrics)と、学習後のモデルが出力する
予測結果が持つ偏り(Post-Training Metrics)を測定、
Pre-Training ではCI/DPL/CDDL, Post-Training では DPPL/DI/DCA/AD/RD/DAR/TE/CDDPI
といった指標が使われるらしい（割と単純な計算式で与えられるものが多い）

予測結果の説明ではKernelSHAPが使われるとのこと。

いずれもこれと言って目新しいものはないが、deployしたモデルの
モニタリング目的で利用できるサービスであるという主張。

## A hyper-surface arrangement model of ranking distributions

- [論文](https://dl.acm.org/doi/10.1145/3447548.3467253)
- [実装](https://github.com/shizuo-kaji/rankLearning) : Chainerを使った実装になっている。

### 概要
九大の鍛冶静雄さんのグループの発表。

アイテムのランキングデータが与えられているときに、このランキングに
最も適合するような多次元空間上の埋め込みを与えるようなアルゴリズムを
考えたという話。Plackett-Luceなどのように1変量にする前提のものは多いが、
ここでは多次元の埋め込みを得られることが利点。

ランキング対象となるアイテム1つが空間上の1点に対応していて、
かつ、空間上の1点がランキング1つに対応しており、その点に近い順に
ランキングが生成されると考える。そのため、アイテムに対応する点で
空間をVoronoi分割すると、Voronoi分割された領域で同一のランキングが
生成される理屈となっている。

神嶌さんの[寿司データセット](https://www.kamishima.net/sushi/)に対して適用した結果が報告されていて、
マグロ系の寿司が概ね同じ地位を占めたり、かっぱ巻きなどが遠くに位置するなど、
概ねデータの全体の傾向を表すような埋め込みベクトルを得ることができるとのこと。

![](./images/KDD2021/HyperSurfaceArrangement.png)

数値検証では、ランキングの上位部分観測から、下位ランキングの推定などが
できるという報告があり、ランキングデータが与えられている場合のレコメンド
などに使えるのではと思った（どういう業種であればランキングデータがあるのかな...）

## Debiasing Learning based Cross-domain Recommendation

- [論文](https://dl.acm.org/doi/10.1145/3447548.3467067)
- 実装はない。

Cross-domain Recommendation といった場合、ユーザが共通する
全く別のデータセットでのレコメンドにおいて、共通ユーザの情報を
互いに使いあうことで精度を高めあうという意味合いが強い。

しかし利用者がオーバーラップするような、2つのネットショッピングサイトで、
まったく同じユーザが、それぞれのサイトで全く別の行動をとることが実際にあり、
これをどのように補正するか？という中国のTaobaoからの報告。

因果グラフにおいて、ドメインに特化した交絡因子(DSC)、共通の交絡因子(GC)
を考える。DSCとして考えられるのが、サイトの性質を表す変数であり、
これによって user embeddings($\boldsymbol{v}_u$) も、購入($y$)も影響を
受けると考えて IPS (傾向スコア逆数スコアリング) でレコメンドの損失に
重みづけをして学習するなどし、バイアス補正の形でドメイン間でのユーザ行動の変化を
吸収したという話。その他いくつかの工夫がある。
評価においては、FM/Wide&Deep/DeepFMに対して提案法を適用し、
従来の Cross-domain Recommendation 手法より精度改善したとのこと。

![](./images/KDD2021/DebiasingCrossDomainRecSys.png)

本当にうまくいったのであれば素晴らしいが、
この結果を出すまでに因果を整理できるかが肝なのだろうと思われ、
実践は難しいだろうなという印象を持った。
